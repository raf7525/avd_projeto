# Projeto AVD - Pipeline de Dados MeteorolÃ³gicos

**DISCIPLINA:** AnÃ¡lise e VisualizaÃ§Ã£o de Dados - 2025.2  
**INSTITUIÃ‡ÃƒO:** CESAR School  

## ğŸ‘¥ Equipe
* **Nome do Aluno 1** (@usuario_github)
* **Nome do Aluno 2** (@usuario_github)
* **Nome do Aluno 3** (@usuario_github)
* **Nome do Aluno 4** (@usuario_github)
* **Nome do Aluno 5** (@usuario_github)
* **Nome do Aluno 6** (@usuario_github)

---

## ğŸ“ DescriÃ§Ã£o do Projeto

Este projeto implementa um pipeline completo de Business Intelligence (BI) e Machine Learning (ML) para anÃ¡lise de dados meteorolÃ³gicos. O objetivo principal Ã© coletar dados, armazenÃ¡-los de forma estruturada e bruta, realizar tratamento, treinar modelos preditivos de **SensaÃ§Ã£o TÃ©rmica** e **Zonas de Conforto**, e visualizar os resultados em dashboards interativos.

### ğŸ¯ Problema Solucionado (SeÃ§Ã£o 7.5 e 7.10)
O sistema resolve o problema de **ClassificaÃ§Ã£o de NÃ­veis de Conforto TÃ©rmico** e **PrevisÃ£o de SensaÃ§Ã£o TÃ©rmica**, permitindo identificar se o ambiente estÃ¡ "Frio", "ConfortÃ¡vel" ou "Quente" com base em variÃ¡veis como temperatura, umidade e vento.

## ğŸ—ï¸ Arquitetura e Fluxo de Dados

O projeto utiliza uma arquitetura baseada em microsserviÃ§os com Docker:

1. **IngestÃ£o (FastAPI + Scripts):** Dados sÃ£o gerados/coletados e enviados para a API (Porta 8060) e para o ThingsBoard.
2. **Armazenamento Bruto (MinIO/S3):** A API salva os dados brutos (JSON) em um bucket S3 (MinIO).
3. **Armazenamento Estruturado (PostgreSQL):** Os dados tratados sÃ£o persistidos em banco relacional (substituindo Snowflake/SQLite para este ambiente).
4. **Processamento e ML (Jupyter + MLflow):** Notebooks consomem os dados, treinam modelos (RegressÃ£o/ClassificaÃ§Ã£o) e registram mÃ©tricas/artefatos no MLflow (Porta 5000).
5. **VisualizaÃ§Ã£o (ThingsBoard + Trendz):** Dashboards consomem dados de telemetria e exibem grÃ¡ficos histÃ³ricos e prediÃ§Ãµes.

| ServiÃ§o | Porta | FunÃ§Ã£o |
|---------|-------|--------|
| **FastAPI** | 8060 | API de IngestÃ£o e PrediÃ§Ã£o |
| **ThingsBoard** | 8080 | Plataforma IoT e Dashboards |
| **Trendz** | 8888 | Analytics AvanÃ§ado |
| **Jupyter** | 1010 | Ambiente de Desenvolvimento |
| **MLflow** | 5000 | Registro de Modelos |
| **MinIO** | 9000/9001 | Object Storage (S3 Compatible) |

## ğŸš€ Como Executar

### PrÃ©-requisitos
- Docker e Docker Compose instalados.
- Git instalado.

### Passo a Passo

1. **Clonar o RepositÃ³rio:**
   ```bash
   git clone <url-do-repositorio>
   cd avd_projeto
   ```

2. **Iniciar a Infraestrutura:**
   O script abaixo levanta todos os containers necessÃ¡rios.
   ```bash
   docker-compose up --build -d
   ```
   *Aguarde alguns minutos para que todos os serviÃ§os (especialmente ThingsBoard e Postgres) inicializem completamente.*

3. **Gerar e Ingerir Dados:**
   Execute os scripts para popular o banco de dados e o ThingsBoard.
   ```bash
   # Instalar dependÃªncias locais dos scripts (opcional, se rodar fora do container)
   pip install -r requirements.txt

   # 1. Gerar dados sintÃ©ticos
   python3 scripts/generate_data.py

   # 2. Ingerir dados na API e ThingsBoard
   python3 scripts/ingest_data.py
   ```

4. **Treinar o Modelo de ML:**
   VocÃª pode treinar o modelo via API ou via Jupyter.
   
   **Via API:**
   ```bash
   curl -X POST "http://localhost:8060/prediction/train"
   ```

   **Via Jupyter:**
   - Acesse `http://localhost:1010` (Token pode ser visto nos logs: `docker-compose logs app`)
   - Abra `notebooks/pipeline_ml.ipynb` e execute as cÃ©lulas.

5. **Acessar os Dashboards:**
   - **ThingsBoard:** Acesse `http://localhost:8080`
     - **Login:** `tenant@thingsboard.org`
     - **Senha:** `tenant`
   - **MLflow:** Acesse `http://localhost:5000` para ver os modelos registrados.
   - **MinIO:** Acesse `http://localhost:9001` (User/Pass: `minioadmin`) para ver os arquivos no bucket `avd-raw-data`.

## ğŸ“‚ Estrutura do RepositÃ³rio

```
/
â”œâ”€â”€ app/                 # CÃ³digo fonte da aplicaÃ§Ã£o (FastAPI)
â”‚   â”œâ”€â”€ main.py          # Entrypoint da API
â”‚   â”œâ”€â”€ routers/         # Rotas da API
â”‚   â””â”€â”€ services/        # LÃ³gica de negÃ³cios e integraÃ§Ãµes
â”œâ”€â”€ data/                # Dados locais (CSV/JSON)
â”œâ”€â”€ docs/                # DocumentaÃ§Ã£o complementar
â”œâ”€â”€ notebooks/           # Notebooks para anÃ¡lise e treino
â”œâ”€â”€ reports/             # RelatÃ³rios PDF e imagens
â”œâ”€â”€ scripts/             # Scripts auxiliares (ingestÃ£o, setup)
â”œâ”€â”€ trendz/              # ConfiguraÃ§Ãµes do Trendz
â”œâ”€â”€ docker-compose.yml   # DefiniÃ§Ã£o dos serviÃ§os
â””â”€â”€ README.md            # Este arquivo
```

## ğŸ§ª Testes e VerificaÃ§Ã£o

Para verificar se a API de prediÃ§Ã£o estÃ¡ funcionando:

```bash
# Teste de prediÃ§Ã£o Ãºnica
curl -X POST "http://localhost:8060/prediction/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "temperature": 28.5,
    "humidity": 70.0,
    "wind_velocity": 5.0,
    "pressure": 1013.0,
    "solar_radiation": 600.0
  }'
```

